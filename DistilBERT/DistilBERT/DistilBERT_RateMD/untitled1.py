# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pTbOkGcamWleItp8X0DYZn2LV8SNshfo
"""

!pip install transformers
!pip install tensorflow
!pip install scikit-learn matplotlib seaborn

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import ast
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification

df = pd.read_csv(next(iter(uploaded)))

df['review'] = df['review'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))
X = df['review'].tolist()
y = df['label'].astype(int).tolist()


class_labels = ['negative', 'neutral', 'positive']


train_ratios = [0.7, 0.8]

tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")

for ratio in train_ratios:
    print(f"\n{'='*40}\nðŸ”¹ EÄŸitim OranÄ±: %{int(ratio*100)}\n{'='*40}")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - ratio, stratify=y, random_state=42)

    train_enc = tokenizer(X_train, truncation=True, padding=True, return_tensors='tf')
    test_enc = tokenizer(X_test, truncation=True, padding=True, return_tensors='tf')

    train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_enc), y_train)).batch(16)
    test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_enc), y_test)).batch(16)

    model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=3)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    model.fit(train_dataset, epochs=2, verbose=1)

    logits = model.predict(test_dataset).logits
    y_pred = np.argmax(logits, axis=1)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='macro')
    rec = recall_score(y_test, y_pred, average='macro')
    f1 = f1_score(y_test, y_pred, average='macro')

    print("\nðŸ”¸ Genel Metrikler:")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1 Score: {f1:.4f}")

    print("\nðŸ”¸ SÄ±nÄ±f BazlÄ± Rapor:\n")
    print(classification_report(y_test, y_pred, target_names=class_labels, digits=4))

    precision_class = precision_score(y_test, y_pred, average=None)
    recall_class = recall_score(y_test, y_pred, average=None)
    f1_class = f1_score(y_test, y_pred, average=None)

    x = np.arange(len(class_labels))
    width = 0.25

    plt.figure(figsize=(10, 6))
    b1 = plt.bar(x - width, precision_class, width, label="Precision")
    b2 = plt.bar(x, recall_class, width, label="Recall")
    b3 = plt.bar(x + width, f1_class, width, label="F1")

    for bars in [b1, b2, b3]:
        for bar in bars:
            yval = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom')

    plt.xticks(ticks=x, labels=class_labels)
    plt.ylim(0, 1.1)
    plt.title(f"DistilBERT SonuÃ§larÄ± (%{int(ratio*100)} EÄŸitim)")
    plt.ylabel("Skor")
    plt.legend()
    plt.tight_layout()
    plt.show()

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel("Tahmin Edilen")
    plt.ylabel("GerÃ§ek")
    plt.title(f"Confusion Matrix (%{int(ratio*100)} EÄŸitim)")
    plt.tight_layout()
    plt.show()